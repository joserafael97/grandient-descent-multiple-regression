{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear Multipla Com Gradiente descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from vega_datasets import data\n",
    "import pandas as pd\n",
    "import random\n",
    "import altair as alt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X, w)\n",
    "    totalError = np.dot(res.T, res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para fazer uma atualização dos parâmetros no Gradiente Descendente:\n",
    "\n",
    "$w^(t+1) = w^(t) − α ∇RSS(w^(t))$\n",
    "\n",
    "Considerando $∇RSS(w^(t)) = −2HT (y−Hw)$ podemos substituír a função principal por:\n",
    "\n",
    "$w^(t+1) = w^(t) − \\alpha(−2HT (y−Hw))$\n",
    "\n",
    "Nesse sentido abaixo é implementada a função que atualiza o valor de W. Onde:\n",
    "\n",
    "learningRate = $\\alpha$\n",
    "\n",
    "H e w é o Hw da formúla\n",
    "\n",
    "Y é o Y da formúla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w, H, Y, learningRate):\n",
    "    gradient = np.multiply(-2, np.dot(H.T, Y - np.dot(H, w)))    \n",
    "    new_w = np.subtract(w, np.multiply(learningRate, gradient))\n",
    "    return [new_w, gradient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    gradient = np.array([np.inf] * len(X[0]))\n",
    "    i = 0\n",
    "    while (np.linalg.norm(gradient) >= epsilon):\n",
    "        w, gradient = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        if i % 50000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,(compute_mse_vectorized(w, X, Y))[0][0]))\n",
    "        i+= 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os dados utilizados\n",
    "Os dados utilizados são as notas de alunos em disciplinas do primeiro período de Computação da UFCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cálculo1</th>\n",
       "      <th>LPT</th>\n",
       "      <th>P1</th>\n",
       "      <th>IC</th>\n",
       "      <th>Cálculo2</th>\n",
       "      <th>cra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.477647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.851724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.090588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.283516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.205747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cálculo1   LPT   P1   IC  Cálculo2       cra\n",
       "0       8.7  10.0  9.0  9.1       8.4  8.477647\n",
       "1       7.0   7.0  7.7  7.0       6.2  6.851724\n",
       "2       8.6   9.8  7.9  9.6       8.7  9.090588\n",
       "3       7.8   8.3  6.8  8.2       8.0  7.283516\n",
       "4       5.2   9.3  5.0  8.5       5.0  7.205747"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = pd.read_csv('sample_treino.csv') #read the data\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução do Algoritmo\n",
    "Abaixo é lido os dados com as notas e CRA dos alunos no primeiro período."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "MSE na iteração 0 é de 13.54011368883012\n",
      "MSE na iteração 50000 é de 0.41731648956775663\n",
      "MSE na iteração 100000 é de 0.413093359156704\n",
      "MSE na iteração 150000 é de 0.4118531904032155\n",
      "MSE na iteração 200000 é de 0.41148900119108417\n",
      "MSE na iteração 250000 é de 0.41138205301821684\n",
      "MSE na iteração 300000 é de 0.41135064650946057\n",
      "Gradiente descendente convergiu com w0 = [1.70515148], w1 = [0.10362486], w2 = [0.04792676], w3 = [0.16402416], w4 = [0.38283179], w5 = [0.02067884], error = [[0.41134501]]\n",
      "Versão vetorizada rodou em: 4558.002710342407 ms\n"
     ]
    }
   ],
   "source": [
    "points = np.genfromtxt(\"sample_treino.csv\", delimiter=\",\")\n",
    "\n",
    "points = np.c_[np.ones(len(points)),points][1::]\n",
    "\n",
    "#Features para predição (Cálculo1,LPT,P1,IC,Cálculo2)\n",
    "X = points[:, :-1]\n",
    "\n",
    "#CRA\n",
    "Y = points[:, -1:]\n",
    "\n",
    "init_w = np.zeros((len(points[0]) - 1,1))\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "epsilon = 0.04\n",
    "\n",
    "print(\"Running...\")\n",
    "tic = time.time()\n",
    "\n",
    "w = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Gradiente descendente convergiu com w0 = {0}, w1 = {1}, w2 = {2}, w3 = {3}, w4 = {4}, w5 = {5}, error = {6}\".format(w[0], w[1], w[2], w[3], w[4], w[5], compute_mse_vectorized(w,X,Y)))\n",
    "print(\"Versão vetorizada rodou em: \" + str(1000*(toc-tic)) + \" ms\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn vs Implementação\n",
    "Abaixo são comparados os valores dos coeficientes obtidos com a execução biblioteca proposta com os obtidos com o algoritmo implementado neste Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes obtidos com a library sklearn:  [[0.10304143 0.0464367  0.16409834 0.38117843 0.02027816]]\n",
      "Intercept obetido com a library sklearn:  [1.73771151]\n",
      "Coeficientes obtidos com o algoritmo implementado: [0.10362486] [0.04792676] [0.16402416] [0.38283179] [0.02067884]\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X[:, 1:], Y)\n",
    "print('Coeficientes obtidos com a library sklearn: ', regr.coef_)\n",
    "print('Intercept obetido com a library sklearn: ', regr.intercept_)\n",
    "print('Coeficientes obtidos com o algoritmo implementado:', w[1], w[2], w[3], w[4], w[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é visto acima o algoritmo implementado obteve valores bastante similares ao produzidos pela library proposta no teste. Logo, podemos considerar que o a implementação está funcionando como o devido."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
